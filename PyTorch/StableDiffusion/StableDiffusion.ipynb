{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f4365f6-6a85-475d-aa3b-13c5dfe5be09",
   "metadata": {},
   "source": [
    "üß† What is Stable Diffusion? (Simple Explanation)\n",
    "Stable Diffusion is a text ‚Üí image generator.\n",
    "It works in 3 big ideas:\n",
    "1. Forward process (noise)\n",
    "    Add noise to an image until it becomes random.\n",
    "\n",
    "2. Reverse process (denoising)\n",
    "    Learn how to remove noise step-by-step using a neural network.\n",
    "\n",
    "3. Text conditioning\n",
    "    The denoising process is guided by text (like ‚Äúa cat wearing shoes‚Äù).\n",
    "\n",
    "üß© Core Components (Big Picture)\n",
    "| Component        | What it does                  |\n",
    "| ---------------- | ----------------------------- |\n",
    "| **Text Encoder** | Converts text ‚Üí numbers       |\n",
    "| **UNet**         | Removes noise step by step    |\n",
    "| **VAE**          | Converts image ‚Üî latent space |\n",
    "| **Scheduler**    | Controls noise removal steps  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d150c15-a858-4903-b7fa-563420b85cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.9.1+cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmad/pytorch/lib/python3.13/site-packages/torch/amp/autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2676f3cb-1bdd-43ea-a734-706f4da7de94",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "diffusers ‚Üí HuggingFace library for diffusion models\n",
    "StableDiffusionPipeline ‚Üí pre-built pipeline combining:\n",
    "    text encoder\n",
    "    UNet\n",
    "    VAE\n",
    "    scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc7ca966-054e-47b9-87e3-5b7aca087dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.float32} are not expected by StableDiffusionPipeline and will be ignored.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "321955f939f64c3cbf0ac97b040230a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 2: Load Pretrained Model (CPU-friendly)\n",
    "#model_id = \"stabilityai/stable-diffusion-2-base\"\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    model_id,\n",
    "    dtype=torch.float32  # CPU uses float32\n",
    ")\n",
    "#pipe = StableDiffusionPipeline.from_pretrained(\n",
    "#    \"hf-internal-testing/tiny-stable-diffusion-pipe\"\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee56604-44d4-4a04-827a-a7474eca5d59",
   "metadata": {},
   "source": [
    "What‚Äôs happening?\n",
    "\n",
    "    Downloads pretrained weights (~4GB)\n",
    "    Loads model architecture + weights\n",
    "    Uses float32 because CPU doesn't support fp16 well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0623177-c3a0-4e20-add0-6e029937b564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 - Move model to CPU, already have CPU but makes explicit\n",
    "pipe = pipe.to(\"cpu\")\n",
    "# üß™ Optional: Reduce Memory Usage\n",
    "# pipe.enable_attention_slicing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c836be88-089c-4363-b7c7-c5d04c43d15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Disable Safety Checker (Optional but good for learning)\n",
    "pipe.safety_checker = None\n",
    "# Avoids unnecessary warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95115eba-23d7-46e0-ad7b-4009693d8de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d15275b7ee4edf84853b4e5fd747d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 5: Generate an Image(Main part)\n",
    "\n",
    "#image = pipe(\"cat with skatter board\").images[0]\n",
    "\n",
    "prompt = \"seamless knitting pattern, textile design, flat surface, top view\"\n",
    "negative_prompt = \"person, human, model, body, mannequin, arms, face\"\n",
    "\n",
    "\n",
    "image = pipe(\n",
    "    prompt=prompt,\n",
    "    negative_prompt=negative_prompt,\n",
    "    num_inference_steps=30,\n",
    "    guidance_scale=7.5\n",
    ").images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ee8ccb-407b-4b70-9e11-fc2dd0877a30",
   "metadata": {},
   "source": [
    "üîç Line-by-Line Explanation\n",
    "prompt\n",
    "Text description ‚Üí converted into embeddings\n",
    "\n",
    "num_inference_steps = 30\n",
    "Number of denoising steps.\n",
    "More steps = better quality but slower.\n",
    "Think:\n",
    "    Noise ‚Üí less noise ‚Üí clearer ‚Üí image\n",
    "    \n",
    "guidance_scale = 7.5\n",
    "Controls how strongly the model follows the text.\n",
    "| Value | Effect                 |\n",
    "| ----- | ---------------------- |\n",
    "| 1‚Äì3   | Very creative, loose   |\n",
    "| 7‚Äì8   | Balanced (recommended) |\n",
    "| 12+   | Overfitting to text    |\n",
    "\n",
    "\n",
    ".images[0]\n",
    "The pipeline returns a list of images.\n",
    "We take the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bd42c89-c718-4a91-b5ae-3215714ae511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Show or Save Image\n",
    "image.show()\n",
    "\n",
    "# or\n",
    "# image.save(\"fashion_output.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch Env",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
