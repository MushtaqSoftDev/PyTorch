{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0ceee04-f466-4647-a31e-2f29d6be168d",
   "metadata": {},
   "source": [
    "# 1. IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b029c4fc-8bc1-4544-90ff-351ef9ef79f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch version: 2.9.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim # Optimizers are algorithms that update nn weights \n",
    "# toolbox of \"learning\" algorithms for neural networks\n",
    "# every time we train, (SGD, Adam, RMSProp) changes the weights so predictions get better\n",
    "from torchvision import datasets, transforms\n",
    "# datasets => gives us prebuilt dataset like (MNIST digits), CIFAT-10, ImageNet\n",
    "# transforms => image preprocessing steps => convert to tensor/resize/normalize/rotate/flip\n",
    "# We only use one transform => transform.toTensor() also scales pixel values from 0-255 => 0-1\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "# DataLoader => takes dataset, cuts it into batches, shuffles it, feeds images to model\n",
    "# Like a machine that hands images to the model 64 at a time.\n",
    "\n",
    "print(\"Pytorch version:\",torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7402b931-0c64-4586-8023-ab9c2fdaf077",
   "metadata": {},
   "source": [
    "# 2. TRANSFORMS\n",
    "- Images are PIL Images (0-255). Neural networks need tensors (0-1).\n",
    "- transform converts each Image into a 28x28 tensor.\n",
    "- Transforms => image preprocessing step=> convert to tensor/resize,,,,etc\n",
    "- Compose=> A list of steps to apply to each image/ It runs transforms in order\n",
    "- combine multiple transforms into one. -  e.g=>transforms.Compose([transforms.Resize((28, 28)), transforms.ToTensor(), transforms.Normalize(0.5, 0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dfa323e-2723-448e-aefc-126df7f811c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform: Compose(\n",
      "    ToTensor()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "print(\"Transform:\", transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c672dc8-9200-474c-a299-572da95ee173",
   "metadata": {},
   "source": [
    "# 3. LOAD DATASET (MNIST)\n",
    "MNIST = handwritten digits 0-9\n",
    "train=True => training images (60,000)\n",
    "train=False => test images (10,000)\n",
    "MNIST images are stored in binary format:\n",
    "train-images-idx3-ubyte\n",
    "train-labels-idx1-ubyte....etc PyTorch reads them internally\n",
    "batch=64 => Mean in each epoch they process 64 images so training happens like\n",
    "1. take 64 images\n",
    "2. compute predictions\n",
    "3. compute loss\n",
    "4. update weights\n",
    "5. take next 64 images\n",
    "6. repeat\n",
    "   This happens until all 60,000 images are used once=>1 epoch\n",
    "shuffle=True=> Shuffling=randomly mixing the data before each epoch\n",
    "Why?\n",
    "B/c if the model sees data in the same order everytime, it might learn patterns based on order, not content.\n",
    "So we shuffle=randomize.\n",
    "* Training loader => shuffle=True\n",
    "* Test loader => shuffle=False(we don't mix test samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13db4ed1-8181-44c5-a154-b4d19b65d584",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 60000\n",
      "Testing samples: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.MNIST(root=\"./data\", train=True, \n",
    "                              download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "print(\"Training samples:\", len(train_dataset))\n",
    "print(\"Testing samples:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ed2a7f-339f-448d-9373-628048f941a2",
   "metadata": {},
   "source": [
    "# 4. SIMPLE NEURAL NETWORK\n",
    "Beginner explanation:\n",
    "- An image is 28x28 = 784 pixels.\n",
    "- We flatten the image into a vector of size 784.\n",
    "- Pass through 2 linear layers.\n",
    "nn.Module => is the base class for ALL PyTorch neural networks.\n",
    "We must inherit from it to create our own model\n",
    "think: nn.Module = parent class\n",
    "SimpleClassifier = our custom model\n",
    "__init__ is the constructor.\n",
    "runs once, when model is created.\n",
    "self = \"this object\", just like this in Java or C#....\n",
    "Inside the constructor we define:\n",
    "* layers\n",
    "* operations\n",
    "* parameters\n",
    "So self.flattern = nn.Flatten()\n",
    "creates a flatten operation.\n",
    "\n",
    "1- Flatten 28x28=>784\n",
    "   self.flatten = nn.Flatten()\n",
    "Images are 28x28.\n",
    "Neural networks want a long vector: 784 numbers.\n",
    "Flatten does that automatically.\n",
    "Before feeding to the 1st fully connected (FC) layer, we flatten it:\n",
    " 28Ã—28  â†’  784 numbers in a 1D vector\n",
    "So the FC layer must take 784 inputs, which is why:\n",
    " nn.Linear(784, 128)\n",
    "\n",
    "\n",
    "2- First fully-connected layer\n",
    "self.fc1 = nn.Linear(28*28, 128)\n",
    "Each MNIST Image is 28x28 pixels, grayscale -> 1 channel.\n",
    "Before feeding to the 1st fully connected (FC) layer, we flatten it:\n",
    "28x28 -> 784 numbers in a 1D vector\n",
    "So the FC layer must take 784 inputs, which is why:\n",
    "nn.Linear(784, 128)\n",
    "Input: 784\n",
    "Output: 128\n",
    "This is hidden layer 1.\n",
    "What is 128 => It is a design choise (a hyperparameter).\n",
    " * Neural networks learn through many neurons.\n",
    " * More neurons =  can learn more complex patterns\n",
    " * Too many neurons = slower + risk of overfitting\n",
    " * Too few neurons = cannot learn enough patterns\n",
    "For MNIST typical choices are:\n",
    "Layer                               Common choices\n",
    "first hidden layer                  64, 128, 256 neurons\n",
    "So... reason for 128 is => it's simply good, commonly used number but also used 64, 256 for MNIST dataset.\n",
    "\n",
    "Why use nn.Linear in a fully connected layer?\n",
    "Fully connected (dense) layers work like:\n",
    " output[i] = w1*x1 + w2*x2 + ... + wn*xn + bias\n",
    "This is a Linear Transformation -> exactly the job of nn.Linear.\n",
    "ðŸ‘‰ A fully connected layer connects every input neuron to every output neuron.\n",
    "That's why we call them Linear layers.\n",
    "\n",
    "\n",
    "3- Second fully-connected layer\n",
    "self.fc2 = nn.Linear(128, 10)\n",
    "128=>10\n",
    "B/c MNIST has 10 classes(digits 0-9)\n",
    "\n",
    "What is forward()?\n",
    "The forward pass describes HOW data flows through network.\n",
    "x = self.flatten(x) => image->flatten\n",
    "x = torch.relu(self.fc1(x)) => pass through first layer -> apply activation (ReLU)\n",
    "Without activation (only Linear):\n",
    "Model is only able to learn a straight line relationship:\n",
    " y = Wx + b\n",
    "This means the network CANNOT learn:\n",
    " * curves,\n",
    " * edges,\n",
    " * shapes,\n",
    " * non-linear patterns.\n",
    "Digit recognition MUST detect curves -> so linear is not enough.\n",
    "ReLU adds non-linearity:\n",
    " ReLU(x) = max(0, x)\n",
    "It turns this: \n",
    " ðŸ“‰ straight line model\n",
    " into\n",
    " ðŸ“ˆ curve + shape learning model\n",
    "This allows the network to learn complex digit shapes.\n",
    "That's why:\n",
    " x = torch.relu(self.fc1(x))\n",
    "\n",
    "x = self.fc2(x) => final output (logits for classes 0-9)\n",
    "The forward method is like describing how electicity flows through a circuit.\n",
    "\n",
    "Component\t                 Why we use it\n",
    "nn.Linear(784, 128)\t         Flattened image has 784 pixels; 128 is chosen (not                                 fixed) to provide enough neurons for learning\n",
    "ReLU activation\t             Allows learning curved/complex shapes instead of just                              straight-line relationships\n",
    "Fully connected (Linear)     Connects all inputs to all outputs â†’ standard NN      layer                         building block                  \n",
    "128 neurons\t                 Good default value, chosen by humans, can be changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7ede756-1cad-4314-9bcf-cc4b78396adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleClassifier(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc2 = fc2 = nn.Linear(128, 10) # 10 digits\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleClassifier()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd98f2a3-21af-4548-9430-1477f1f530b9",
   "metadata": {},
   "source": [
    "# 5. LOSS & OPTIMIZER\n",
    "- CrossEntropyLoss = best for classification\n",
    "- Adam = modern optimizer\n",
    "We are going to use CrossEntropyLoss instead of MSE (Mean Squared Error) b/c\n",
    " MSE\n",
    " * used for regression (predicting numbers), like:\n",
    " * house price\n",
    " * temperature\n",
    " * stock price\n",
    "Not good for classification b/c it does not understand classes.\n",
    "\n",
    " CrossEntropyLoss\n",
    " * Used for classification, especially when:\n",
    " * Output = class scores\n",
    " * Labels = class index (0-9)\n",
    "This loss automatically:\n",
    " * applies Softmax (convers scores -> probabilities)\n",
    " * compares predicted probability vs. correct label\n",
    " * gives higher loss when model is wrong\n",
    "MSE = for numbers\n",
    "CrossEntropy = for categories (like digits)\n",
    "\n",
    "\n",
    "What is model.parameters()?\n",
    "When we create a model:\n",
    "    class SimpleClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "Inside each nn.Linear, PyTorch creates:\n",
    " * weigths\n",
    " * biases\n",
    "These are the learnable values simply means: ðŸ‘‰ â€œGive me all weights and biases in the model so I can update them.â€\n",
    "\n",
    "What is lr=0.001?\n",
    "lr = learning rate\n",
    "It controls how big the weight updates are.\n",
    "Simple example:\n",
    " New weight = Old weight - lr * gradient\n",
    "* lr = 1.0 -> huge steps (too fast, unstable)\n",
    "* lr = 0.0000001 -> tiny steps (training very slow)\n",
    "* lr = 0.001 -> very common good value\n",
    "So:\n",
    "ðŸ‘‰ Learning rate decides how fast the model learns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ff2a546-cc2c-4113-b8cc-db03d8922ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7723a732-b780-487a-8274-2add0e29163e",
   "metadata": {},
   "source": [
    "# 6. TRAINING LOOP\n",
    "STEPS:\n",
    " 1. Loop over batches\n",
    " 2. Forward pass => model(x)\n",
    " 3. Compute loss\n",
    " 4. Zero gradients\n",
    " 5. Backprop\n",
    " 6. Update weights\n",
    "What is an epoch?\n",
    "One epoch = model sees ALL training images once\n",
    "We decide the number:\n",
    " * Too small -> model doesn't learn enough\n",
    " * Too large -> model overfits / wastes time\n",
    "\n",
    "Common values: 5, 10, 20.\n",
    "\n",
    "What is model.train()?\n",
    "PyTorch models have 2 modes:\n",
    ".train() -> during training -> enables dropout, batchnorm updates\n",
    ".eval() -> during testing -> disables dropout etc.\n",
    "Even if model doesn't use dropout, it is good practice.\n",
    "\n",
    "What is train_loader?\n",
    "When we write at step 3:\n",
    " => train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "This:\n",
    "  * takes all 60,000 MNIST images\n",
    "\n",
    "  * groups them in batches of 64 images\n",
    "\n",
    "  * randomizes order (because shuffle=True)\n",
    "\n",
    "  * each loop gives:\n",
    "      images = a batch of 64 images\n",
    "      labels = 64 corresponding digit labels\n",
    "\n",
    "So:\n",
    " for images, labels in train_loader:\n",
    "means;\n",
    "Each iteration gives 64 images + 64 correct answers.\n",
    "\n",
    "Explanation of inside loop:\n",
    " 1. outputs = model(images)\n",
    "Feed one batch of images into the model.\n",
    "THe model gives predicted class scores for each image.\n",
    "\n",
    "2. loss = loss_fn(outputs, labels)\n",
    "\n",
    "Compare predictions vs. true labels.\n",
    "\n",
    "CrossEntropyLoss does:\n",
    "\n",
    "Softmax to convert scores â†’ probabilities\n",
    "\n",
    "Computes loss based on how wrong predictions are\n",
    "\n",
    "3. optimizer.zero_grad()\n",
    "\n",
    "IMPORTANT STEP.\n",
    "\n",
    "Gradients accumulate, so before computing new gradients:\n",
    "\n",
    "ðŸ‘‰ we reset old gradients to zero\n",
    "\n",
    "âœ” 4. loss.backward()\n",
    "\n",
    "This:\n",
    "\n",
    "Computes the gradient for EACH weight\n",
    "\n",
    "Figure out which direction reduces loss\n",
    "\n",
    "Think:\n",
    "  Which changes will make the model better?\n",
    "\n",
    "âœ” 5. optimizer.step()\n",
    "\n",
    "This is where LEARNING happens.\n",
    "\n",
    "Using gradient info:\n",
    " new_weight = old_weight - lr * gradient\n",
    "Adam does this in a smart way (better than simple SGD).\n",
    "\n",
    "âœ” 6. total_loss += loss.item()\n",
    "\n",
    "We collect the loss of all batches to print avg loss per epoch.\n",
    "\n",
    "ðŸŽ¯ SUPER SIMPLE SUMMARY\n",
    "| Code                                             | Meaning                                  |\n",
    "| ------------------------------------------------ | ---------------------------------------- |\n",
    "| `loss_fn = CrossEntropyLoss()`                   | For classification problems              |\n",
    "| `optimizer = Adam(model.parameters(), lr=0.001)` | Updates weights using gradients          |\n",
    "| `model.train()`                                  | Sets model to training mode              |\n",
    "| `train_loader`                                   | Gives batches of 64 images + labels      |\n",
    "| `optimizer.zero_grad()`                          | Clears old gradients                     |\n",
    "| `loss.backward()`                                | Computes new gradients                   |\n",
    "| `optimizer.step()`                               | Updates all model weights                |\n",
    "| `epoch`                                          | How many times model sees entire dataset |\n",
    "\n",
    "\n",
    "\n",
    "Basic Concept:\n",
    "ðŸ“Œ Step-by-step example\n",
    "\n",
    "MNIST = 60,000 images\n",
    "Batch size = 64\n",
    "In one epoch:\n",
    "  Batch 1 â†’ images 0â€“63  \n",
    "  Batch 2 â†’ images 64â€“127  \n",
    "  Batch 3 â†’ images 128â€“191  \n",
    "  ...\n",
    "  Batch 937 â†’ images 59936â€“60000\n",
    "  \n",
    "Then:\n",
    "Epoch 2 starts\n",
    "\n",
    "Again from image 0 to 60000\n",
    "But this time the model is already better because weights were updated after each batch in epoch 1.\n",
    "âœ” Why do this multiple epochs?\n",
    "\n",
    "Because:\n",
    "\n",
    "ðŸ‘‰ The more the model sees the data, the better the learning.\n",
    "\n",
    "Training is repetition.\n",
    "\n",
    "Batch_size = 64 \n",
    "decide how many images model processes at one time.\n",
    "Think of it like this:\n",
    "\n",
    "ðŸ“¦ The full dataset = 60,000 images\n",
    "ðŸ“¦ Batch size = 64\n",
    "\n",
    "So in one epoch, the model process the dataset in small chunks:\n",
    " 60000 images Ã· 64 per batch â‰ˆ 937 batches\n",
    "So in one epoch, the loop runs 937 times.\n",
    "Each iteration:\n",
    " images â†’ tensor of shape (64, 1, 28, 28)\n",
    " labels â†’ tensor of shape (64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7370ab62-0131-4306-b642-6998fc540a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 => Loss: 27.6601\n",
      "Epoch 2/15 => Loss: 23.2200\n",
      "Epoch 3/15 => Loss: 19.9619\n",
      "Epoch 4/15 => Loss: 15.3851\n",
      "Epoch 5/15 => Loss: 14.0172\n",
      "Epoch 6/15 => Loss: 11.9478\n",
      "Epoch 7/15 => Loss: 9.2649\n",
      "Epoch 8/15 => Loss: 7.9288\n",
      "Epoch 9/15 => Loss: 8.1957\n",
      "Epoch 10/15 => Loss: 6.6669\n",
      "Epoch 11/15 => Loss: 4.3433\n",
      "Epoch 12/15 => Loss: 5.4909\n",
      "Epoch 13/15 => Loss: 3.6643\n",
      "Epoch 14/15 => Loss: 5.2104\n",
      "Epoch 15/15 => Loss: 2.0508\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()  # reset\n",
    "        loss.backward()        # compute gradients\n",
    "        optimizer.step()       # update\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} => Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06472b1-78a7-4691-b8bc-9f7ecac59106",
   "metadata": {},
   "source": [
    "# 7. EVALUATION\n",
    "During evaluation, we check how well our model performs on data it has never seen before (test set).\n",
    "1st initialize counters: \n",
    "correct = 0, number of correctly predicted images\n",
    "total = 0, total number of test images\n",
    "We will use these to calculate accuracy.\n",
    "2nd set model to evaluation mode:\n",
    " model.eval()\n",
    "Why?\n",
    "âœ” Turns off dropout\n",
    "âœ” Turns off batch normalization updates\n",
    "\n",
    "(You donâ€™t need these during testing)\n",
    "\n",
    "Training mode â‰  Evaluation mode\n",
    "\n",
    "3rd: Disable gradient calculation:\n",
    " with torch.no_grad():\n",
    "During testing â†’ we do NOT update weights\n",
    "\n",
    "So we donâ€™t need gradients\n",
    "\n",
    "This makes evaluation faster and uses less memory\n",
    "\n",
    "4th Loop through the test data:\n",
    " for images, labels in test_loader:\n",
    "images = batch of images from test set\n",
    "\n",
    "labels = true answers (digits 0â€“9)\n",
    "\n",
    "Remember:\n",
    "test_loader yields batches (e.g., 64 images at a time)\n",
    "\n",
    "5th. Pass the images through the model:\n",
    " outputs = model(images)\n",
    " \n",
    "The model generates 10 numbers per image\n",
    "These are the scores for digits 0â€“9\n",
    "Example output for one image might look like:\n",
    " [-1.2, 0.3, 4.5, 2.1, -0.7, 1.0, 0.9, -2.0, 3.1, 0.5]\n",
    "The largest score is the predicted digit.\n",
    "\n",
    "\n",
    "6th. Find the predicted digit:\n",
    " predictions = torch.argmax(outputs, dim=1)\n",
    " \n",
    "argmax returns the index of the highest number\n",
    "dim=1 means \"choose the max from the 10 output classes\"\n",
    "\n",
    "Example:\n",
    " outputs for 1 image: [-1, 0, 2, 0.5, -2, 1, 0.7, -1, 0.3, 0.2]\n",
    " argmax â†’ 2\n",
    "So prediction = digit 2.\n",
    "\n",
    "7th. Count correct predictions:\n",
    " correct += (predictions == labels).sum().item()\n",
    "\n",
    "(predictions == labels) â†’ boolean tensor (True/False)\n",
    ".sum() â†’ counts True values\n",
    "We add this to our correct counter\n",
    "\n",
    "8th. Count total images:\n",
    " total += labels.size(0)\n",
    "* labels.size(0) = batch size\n",
    "   (e.g., 64 images)\n",
    "\n",
    "9th. Calculate accuracy\n",
    "   0.95 -> 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4dc2deba-ebd7-491d-b2bb-72dd286533ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.979\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        correct += (predictions == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(\"Test Accuracy:\", correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775abe4e-39dd-4dce-a69a-0b195d61b7a8",
   "metadata": {},
   "source": [
    "# 8. PREDICT A SINGLE IMAGE\n",
    "  example_img, example_label = test_dataset[3]\n",
    "  * Get the 4th image (index 3)\n",
    "  * example_img -> image tensor (shape: [1, 28, 28])\n",
    "  * example_label -> correct digit (0-9)\n",
    "\n",
    "Add batch dimension:\n",
    "  example_img.unsqueeze(0)\n",
    "Why?\n",
    "The model expects shape:\n",
    "  (batch_size, channels, height, width)\n",
    "Our image shape:\n",
    "  (1, 28, 28)\n",
    "After unsqueeze:\n",
    " (1, 1, 28, 28)\n",
    "Now it looks like a batch of 1 image.\n",
    "\n",
    "Pass through model:\n",
    " output = model(...)\n",
    "Model gives 10 numbers (one for each digit).\n",
    "\n",
    "Select best prediction\n",
    " pred = torch.argmax(output)\n",
    "\n",
    "\n",
    " .item() converts tensor -> Python number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b23a7bce-78ab-4fb8-a8b5-af04d0982491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Label: 0\n",
      "Predicted: 0\n"
     ]
    }
   ],
   "source": [
    "example_img, example_label = test_dataset[3]\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(example_img.unsqueeze(0)) # add batch dimension\n",
    "    pred = torch.argmax(output)\n",
    "\n",
    "print(\"True Label:\", example_label)\n",
    "print(\"Predicted:\", pred.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch Env",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
